{
    "url_original": "https://www.wsj.com/articles/chatbot-consumers-smart-11621535198?mod=tech_featst_pos1",
    "url": "chatbot-consumers-smart-11621535198",
    "title": "Consumers Like Chatbots to Be Smart—but Not Too Smart",
    "sub_head": "If the chatbot seems overconfident or arrogant, users are turned off",
    "category_1": "Business",
    "category_2": "Journal Reports: Leadership",
    "image_1_url": "https://images.wsj.net/im-341404?width=620&size=1.5",
    "image_1": "im-341404.jpg",
    "time": "2021-05-21 13:00:00",
    "body": "In the Customer Experience report, we look at the many ways companies and consumers interact and how companies might make those experiences better for consumers. Previous coverage and new stories running this week can be found here.<br />Attention, IT designers: Making chatbots seem too smart could be off-putting to users. But if you make them seem too dumb, people are unlikely to give them a try.<br />The need to strike a proper balance is one takeaway from new research into how humans interact with chatbots.People tend to be more critical of chatbots, the research found, if the bot immediately projects arrogance or overconfidence. But they’re less likely to try it out in the first place if they don’t have faith in the chatbot’s competence.<br />“It is a double-edged sword,” says Ranjay Krishna, a Ph.D. candidate in the computer-science department at Stanford University and one of the study’s researchers.<br />The research, published in October at the ACM Conference on Computer-Supported Cooperative Work and Social Computing, is based on three studies in which nearly 300 participants interacted with an AI agent. In the studies, chatbots were described differently when introduced to a study participant. The chatbots could be described as being like a “toddler,” “middle schooler,” “young student,” “recent graduate,” “trained professional,” “inexperienced teenager” or “shrewd travel executive.”"
}